{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# TensorFlow基础"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-07 15:24:57.765496: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-07-07 15:24:59.837191: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2024-07-07 15:24:59.849723: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2024-07-07 15:24:59.929978: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-07 15:24:59.930100: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 4060 Ti computeCapability: 8.9\n",
      "coreClock: 2.535GHz coreCount: 34 deviceMemorySize: 7.75GiB deviceMemoryBandwidth: 268.25GiB/s\n",
      "2024-07-07 15:24:59.930114: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-07-07 15:24:59.974808: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2024-07-07 15:24:59.974879: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2024-07-07 15:24:59.998275: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2024-07-07 15:25:00.004338: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2024-07-07 15:25:00.048136: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-07-07 15:25:00.055122: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2024-07-07 15:25:00.146154: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-07-07 15:25:00.146450: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-07 15:25:00.146796: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-07 15:25:00.147009: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据类型\n",
    "\n",
    "### 数值类型\n",
    "\n",
    "标量在 TensorFlow 是如何创建的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python 语言方式创建标量\n",
    "a = 1.2 \n",
    "# TF 方式创建标量\n",
    "aa = tf.constant(1.2)\n",
    "\n",
    "type(a), type(aa), tf.is_tensor(aa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果要使用 TensorFlow 提供的功能函数， 须通过 TensorFlow 规定的方式去创建张量，而不能使用 Python 语言的标准变量创建方式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([1,2.,3.3])\n",
    "# 打印 TF 张量的相关信息                \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将 TF 张量的数据导出为 numpy 数组格式\n",
    "x.numpy() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "与标量不同，向量的定义须通过 List 容器传给 tf.constant()函数。\n",
    "\n",
    "创建一个元素的向量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个元素的向量\n",
    "a = tf.constant([1.2]) \n",
    "a, a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建 3 个元素的向量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # 创建 3 个元素的向量\n",
    "a = tf.constant([1,2, 3.])\n",
    "a, a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建 2 行 2 列的矩阵\n",
    "a = tf.constant([[1,2],[3,4]]) \n",
    "a, a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "三维张量可以定义为："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建 3 维张量\n",
    "tf.constant([[[1,2],[3,4]],[[5,6],[7,8]]]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过传入字符串对象即可创建字符串类型的张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建字符串\n",
    "a = tf.constant('Hello, Deep Learning.') \n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 字符串类型\n",
    "\n",
    "通过传入字符串对象即可创建字符串类型的张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建字符串\n",
    "a = tf.constant('Hello, Deep Learning.') \n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在 tf.strings 模块中，提供了常见的字符串类型的工具函数，如小写化 lower()、 拼接\n",
    "join()、 长度 length()、 切分 split()等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 小写化字符串\n",
    "tf.strings.lower(a) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 布尔类型\n",
    "布尔类型的张量只需要传入 Python 语言的布尔类型数据，转换成 TensorFlow 内部布尔型即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建布尔类型标量\n",
    "tf.constant(True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建布尔类型的向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # 创建布尔类型向量\n",
    "tf.constant([True, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要注意的是， TensorFlow 的布尔类型和 Python 语言的布尔类型并不等价，不能通用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建 TF 布尔张量\n",
    "a = tf.constant(True) \n",
    "# TF 布尔类型张量与 python 布尔类型比较\n",
    "print(a is True) \n",
    "# 仅数值比较\n",
    "print(a == True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数值精度\n",
    "\n",
    "在创建张量时，可以指定张量的保存精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建指定精度的张量\n",
    "tf.constant(123456789, dtype=tf.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.constant(123456789, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于浮点数， 高精度的张量可以表示更精准的数据，例如采用 tf.float32 精度保存π时，实际保存的数据为 3.1415927"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 从 numpy 中导入 pi 常量\n",
    "np.pi \n",
    "# 32 位\n",
    "tf.constant(np.pi, dtype=tf.float32) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果采用 tf.float64 精度保存π，则能获得更高的精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.constant(np.pi, dtype=tf.float64) # 64 位"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取精度\n",
    "\n",
    "通过访问张量的 dtype 成员属性可以判断张量的保存精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant(np.pi, dtype=tf.float16)\n",
    "\n",
    "# 读取原有张量的数值精度\n",
    "print('before:',a.dtype) \n",
    "# 如果精度不符合要求，则进行转换\n",
    "if a.dtype != tf.float32: \n",
    "    # tf.cast 函数可以完成精度转换\n",
    "    a = tf.cast(a,tf.float32) \n",
    "# 打印转换后的精度\n",
    "print('after :',a.dtype) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 类型转换\n",
    "系统的每个模块使用的数据类型、 数值精度可能各不相同， 对于不符合要求的张量的类型及精度， 需要通过 tf.cast 函数进行转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建 tf.float16 低精度张量\n",
    "a = tf.constant(np.pi, dtype=tf.float16) \n",
    "# 转换为高精度张量\n",
    "tf.cast(a, tf.double) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "进行类型转换时，需要保证转换操作的合法性， 例如将高精度的张量转换为低精度的张量时，可能发生数据溢出隐患："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant(123456789, dtype=tf.int32)\n",
    "# 转换为低精度整型\n",
    "tf.cast(a, tf.int16) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "布尔类型与整型之间相互转换也是合法的， 是比较常见的操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant([True, False])\n",
    "# 布尔类型转整型\n",
    "tf.cast(a, tf.int32) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般默认 0 表示 False， 1 表示 True，在 TensorFlow 中，将非 0 数字都视为 True，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant([-1, 0, 1, 2])\n",
    "# 整型转布尔类型\n",
    "tf.cast(a, tf.bool) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 待优化张量\n",
    "\n",
    "TensorFlow 增加了一种专门的数据类型来支持梯度信息的记录： tf.Variable。 tf.Variable 类型在普通的张量类型基础上添加了 name， trainable 等属性来支持计算图的构建。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建 TF 张量\n",
    "a = tf.constant([-1, 0, 1, 2]) \n",
    "# 转换为 Variable 类型\n",
    "aa = tf.Variable(a) \n",
    "# Variable 类型张量的属性\n",
    "aa.name, aa.trainable "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "name 属性用于命名计算图中的变量，这套命名体系是 TensorFlow 内部维护的， 一般不需要用户关注 name 属性；   \n",
    "trainable属性表征当前张量是否需要被优化，创建 Variable 对象时是默认启用优化标志，可以设置trainable=False 来设置张量不需要优化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接创建 Variable 张量\n",
    "tf.Variable([[1,2],[3,4]]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建张量\n",
    "\n",
    "### 从数组、列表对象创建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过 tf.convert_to_tensor 函数可以创建新 Tensor，并将保存在 Python List 对象或者Numpy Array 对象中的数据导入到新 Tensor 中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从列表创建张量\n",
    "tf.convert_to_tensor([1,2.]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从数组中创建张量\n",
    "tf.convert_to_tensor(np.array([[1,2.],[3,4]])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建全0或全1张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建全 0，全 1 的标量\n",
    "tf.zeros([]),tf.ones([]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建全 0，全 1 的向量\n",
    "tf.zeros([1]),tf.ones([1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建全 0 的矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建全 0 矩阵，指定 shape 为 2 行 2 列\n",
    "tf.zeros([2,2]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建全 1 的矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建全 1 矩阵，指定 shape 为 3 行 2 列\n",
    "tf.ones([3,2]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过 tf.zeros_like, tf.ones_like 可以方便地新建与某个张量 shape 一致， 且内容为全 0 或全 1 的张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个矩阵\n",
    "a = tf.ones([2,3]) \n",
    "# 创建一个与 a 形状相同，但是全 0 的新矩阵\n",
    "tf.zeros_like(a) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建与张量A形状一样的全 1 张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个矩阵\n",
    "a = tf.zeros([3,2]) \n",
    "# 创建一个与 a 形状相同，但是全 1 的新矩阵\n",
    "tf.ones_like(a) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建自定义数值张量\n",
    "\n",
    "通过 tf.fill(shape, value)可以创建全为自定义数值 value 的张量，形状由 shape 参数指定。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建-1 的标量\n",
    "tf.fill([], -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建-1 的向量\n",
    "tf.fill([1], -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建 2 行 2 列，元素全为 99 的矩阵\n",
    "tf.fill([2,2], 99) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建已知分布的张量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过 tf.random.normal(shape, mean=0.0, stddev=1.0)可以创建形状为 shape，均值为mean，标准差为 stddev 的正态分布$\\mathcal{N}(mean, stddev^2)$。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建标准正态分布的张量\n",
    "tf.random.normal([2,2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建均值为 1，标准差为 2 的正态分布的张量\n",
    "tf.random.normal([2,2], mean=1,stddev=2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过 tf.random.uniform(shape, minval=0, maxval=None, dtype=tf.float32)可以创建采样自[minval, maxval)区间的均匀分布的张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建采样自[0,1)均匀分布的矩阵\n",
    "tf.random.uniform([3,2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建采样自[0,10)均匀分布的矩阵\n",
    "tf.random.uniform([2,2],maxval=10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果需要均匀采样整形类型的数据，必须指定采样区间的最大值 maxval 参数，同时指定数据类型为 tf.int*型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建采样自[0,100)均匀分布的整型矩阵\n",
    "tf.random.uniform([2,2],maxval=100,dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建序列\n",
    "\n",
    "tf.range(limit, delta=1)可以创建[0, limit)之间，步长为 delta 的整型序列，不包含 limit 本身。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0~10，不包含 10\n",
    "tf.range(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建 0~10，步长为 2 的整形序列\n",
    "tf.range(10,delta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.range(1,10,delta=2) # 1~10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 张量的典型应用\n",
    "\n",
    "### 标量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机模拟网络输出\n",
    "out = tf.random.uniform([4,10]) \n",
    "# 随机构造样本真实标签\n",
    "y = tf.constant([2,3,2,0]) \n",
    "# one-hot 编码\n",
    "y = tf.one_hot(y, depth=10) \n",
    "# 计算每个样本的 MSE\n",
    "loss = tf.keras.losses.mse(y, out) \n",
    "# 平均 MSE,loss 应是标量\n",
    "loss = tf.reduce_mean(loss) \n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 向量\n",
    "\n",
    "考虑 2 个输出节点的网络层， 我们创建长度为 2 的偏置向量b，并累加在每个输出节点上："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z=wx,模拟获得激活函数的输入 z\n",
    "z = tf.random.normal([4,2])\n",
    "# 创建偏置向量\n",
    "b = tf.zeros([2])\n",
    "# 累加上偏置向量\n",
    "z = z + b \n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建输入节点数为 4，输出节点数为 3 的线性层网络，那么它的偏置向量 b 的长度应为 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一层 Wx+b，输出节点为 3\n",
    "fc = tf.keras.layers.Dense(3) \n",
    "# 通过 build 函数创建 W,b 张量，输入节点为 4\n",
    "fc.build(input_shape=(2,4))\n",
    "# 查看偏置向量\n",
    "fc.bias "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 个样本，特征长度为 4 的张量\n",
    "x = tf.random.normal([2,4]) \n",
    "# 定义 W 张量\n",
    "w = tf.ones([4,3])\n",
    "# 定义 b 张量\n",
    "b = tf.zeros([3]) \n",
    "# X@W+b 运算\n",
    "o = x@w+b \n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义全连接层的输出节点为 3\n",
    "fc = tf.keras.layers.Dense(3) \n",
    "# 定义全连接层的输入节点为 4\n",
    "fc.build(input_shape=(2,4)) \n",
    "# 查看权值矩阵 W\n",
    "fc.kernel "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 三维张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自动加载 IMDB 电影评价数据集\n",
    "(x_train,y_train),(x_test,y_test)=keras.datasets.imdb.load_data(num_words=10000)\n",
    "# 将句子填充、截断为等长 80 个单词的句子\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train,maxlen=80)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到 x_train 张量的 shape 为[25000,80]，其中 25000 表示句子个数， 80 表示每个句子共 80 个单词，每个单词使用数字编码方式表示。\n",
    "\n",
    "我们通过 layers.Embedding 层将数字编码的单词转换为长度为 100 个词向量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建词向量 Embedding 层类\n",
    "embedding = tf.keras.layers.Embedding(10000, 100)\n",
    "# 将数字编码的单词转换为词向量\n",
    "out = embedding(x_train)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，经过 Embedding 层编码后，句子张量的 shape 变为[25000,80,100]，其中 100 表示每个单词编码为长度是 100 的向量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 四维张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 创建 32x32 的彩色图片输入，个数为 4\n",
    "x = tf.random.normal([4,32,32,3])\n",
    "# 创建卷积神经网络\n",
    "layer = layers.Conv2D(16, kernel_size=3)\n",
    "# 前向计算\n",
    "out = layer(x) \n",
    "# 输出大小\n",
    "out.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 访问卷积核张量\n",
    "layer.kernel.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 索引与切片\n",
    "### 索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建4维张量\n",
    "x = tf.random.normal([4,32,32,3]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 取第 1 张图片的数据\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 取第 1 张图片的第 2 行\n",
    "x[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取第 1 张图片，第 2 行，第 3 列的数据\n",
    "x[0][1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取第 3 张图片，第 2 行，第 1 列的像素， B 通道(第 2 个通道)颜色强度值\n",
    "x[2][1][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取第 2 张图片，第 10 行，第 3 列的数据\n",
    "x[1,9,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 切片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 读取第 2,3 张图片\n",
    "x[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 读取第一张图片\n",
    "x[0,::] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[:,0:28:2,0:28:2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 考虑一个 0~9 的简单序列向量， 逆序取到第 1 号元素，不包含第 1 号\n",
    "# 创建 0~9 向量\n",
    "x = tf.range(9) \n",
    "# 从 8 取到 0，逆序，不包含 0\n",
    "x[8:0:-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 逆序全部元素\n",
    "x[::-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 逆序间隔采样\n",
    "x[::-2] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取每张图片的所有通道，其中行按着逆序隔行采样，列按着逆序隔行采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.normal([4,32,32,3])\n",
    "# 行、列逆序间隔采样\n",
    "x[0,::-2,::-2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 取 G 通道数据\n",
    "x[:,:,:,1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 读取第 1~2 张图片的 G/B 通道数据\n",
    "# 高宽维度全部采集\n",
    "x[0:2,...,1:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 读取最后 2 张图片\n",
    "# 高、宽、通道维度全部采集，等价于 x[2:]\n",
    "x[2:,...] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取 R/G 通道数据\n",
    "# 所有样本，所有高、宽的前 2 个通道\n",
    "x[...,:2] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 维度变换\n",
    "\n",
    "### 改变视图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 生成向量\n",
    "x=tf.range(96)\n",
    "# 改变 x 的视图，获得 4D 张量，存储并未改变\n",
    "x=tf.reshape(x,[2,4,4,3]) \n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 改变视图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们通过 tf.range()模拟生成一个向量数据，并通过 tf.reshape 视图改变函数产生不同的视图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 生成向量\n",
    "x = tf.range(96) \n",
    "# 改变 x 的视图，获得 4D 张量，存储并未改变\n",
    "x = tf.reshape(x,[2,4,4,3]) \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取张量的维度数和形状列表\n",
    "x.ndim,x.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过 tf.reshape(x, new_shape)，可以将张量的视图任意地合法改变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reshape(x,[2,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " tf.reshape(x,[2,4,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.reshape(x,[2,-1,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 增、删维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 产生矩阵\n",
    "x = tf.random.uniform([28,28],maxval=10,dtype=tf.int32)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过 tf.expand_dims(x, axis)可在指定的 axis 轴前可以插入一个新的维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# axis=2 表示宽维度后面的一个维度\n",
    "x = tf.expand_dims(x,axis=2) \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.expand_dims(x,axis=0) # 高维度之前插入新维度\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.squeeze(x, axis=0) # 删除图片数量维度\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = tf.random.uniform([1,28,28,1],maxval=10,dtype=tf.int32)\n",
    "tf.squeeze(x) # 删除所有长度为 1 的维度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 交换维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = tf.random.normal([2,32,32,3])\n",
    "# 交换维度\n",
    "tf.transpose(x,perm=[0,3,1,2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = tf.random.normal([2,32,32,3])\n",
    "# 交换维度\n",
    "tf.transpose(x,perm=[0,2,1,3]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 复制数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建向量 b\n",
    "b = tf.constant([1,2]) \n",
    "# 插入新维度，变成矩阵\n",
    "b = tf.expand_dims(b, axis=0) \n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 样本维度上复制一份\n",
    "b = tf.tile(b, multiples=[2,1]) \n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.range(4)\n",
    "# 创建 2 行 2 列矩阵\n",
    "x=tf.reshape(x,[2,2]) \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 列维度复制一份\n",
    "x = tf.tile(x,multiples=[1,2]) \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 行维度复制一份\n",
    "x = tf.tile(x,multiples=[2,1]) \n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 创建矩阵\n",
    "A = tf.random.normal([32,1]) \n",
    "# 扩展为 4D 张量\n",
    "tf.broadcast_to(A, [2,32,32,3]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = tf.random.normal([32,2])\n",
    "# 不符合 Broadcasting 条件\n",
    "try: \n",
    "    tf.broadcast_to(A, [2,32,32,4])\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数学运算\n",
    "\n",
    "### 加、减、乘、除运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.range(5)\n",
    "b = tf.constant(2)\n",
    "# 整除运算\n",
    "a//b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 余除运算\n",
    "a%b "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 乘方运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.range(4)\n",
    "# 乘方运算\n",
    "tf.pow(x,3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 乘方运算符\n",
    "x**2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tf.constant([1.,4.,9.])\n",
    "# 平方根\n",
    "x**(0.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.range(5)\n",
    "# 转换为浮点数\n",
    "x = tf.cast(x, dtype=tf.float32) \n",
    "# 平方\n",
    "x = tf.square(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 平方根\n",
    "tf.sqrt(x) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 指数和对数运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([1.,2.,3.])\n",
    "# 指数运算\n",
    "2**x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自然指数运算\n",
    "tf.exp(1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.exp(3.)\n",
    "# 对数运算\n",
    "tf.math.log(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([1.,2.])\n",
    "x = 10**x\n",
    "# 换底公式\n",
    "tf.math.log(x)/tf.math.log(10.) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 矩阵相乘运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.random.normal([4,3,28,32])\n",
    "b = tf.random.normal([4,3,32,2])\n",
    "# 批量形式的矩阵相乘\n",
    "a@b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = tf.random.normal([4,28,32])\n",
    "b = tf.random.normal([32,16])\n",
    "# 先自动扩展，再矩阵相乘\n",
    "tf.matmul(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前向传播实战"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.datasets as datasets\n",
    "\n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams['font.family'] = ['STKaiti']\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # 加载 MNIST 数据集\n",
    "    (x, y), (x_val, y_val) = datasets.mnist.load_data()\n",
    "    # 转换为浮点张量， 并缩放到-1~1\n",
    "    x = tf.convert_to_tensor(x, dtype=tf.float32) / 255.\n",
    "    # 转换为整形张量\n",
    "    y = tf.convert_to_tensor(y, dtype=tf.int32)\n",
    "    # one-hot 编码\n",
    "    y = tf.one_hot(y, depth=10)\n",
    "\n",
    "    # 改变视图， [b, 28, 28] => [b, 28*28]\n",
    "    x = tf.reshape(x, (-1, 28 * 28))\n",
    "\n",
    "    # 构建数据集对象\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    # 批量训练\n",
    "    train_dataset = train_dataset.batch(200)\n",
    "    return train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_paramaters():\n",
    "    # 每层的张量都需要被优化，故使用 Variable 类型，并使用截断的正太分布初始化权值张量\n",
    "    # 偏置向量初始化为 0 即可\n",
    "    # 第一层的参数\n",
    "    w1 = tf.Variable(tf.random.truncated_normal([784, 256], stddev=0.1))\n",
    "    b1 = tf.Variable(tf.zeros([256]))\n",
    "    # 第二层的参数\n",
    "    w2 = tf.Variable(tf.random.truncated_normal([256, 128], stddev=0.1))\n",
    "    b2 = tf.Variable(tf.zeros([128]))\n",
    "    # 第三层的参数\n",
    "    w3 = tf.Variable(tf.random.truncated_normal([128, 10], stddev=0.1))\n",
    "    b3 = tf.Variable(tf.zeros([10]))\n",
    "    return w1, b1, w2, b2, w3, b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(epoch, train_dataset, w1, b1, w2, b2, w3, b3, lr=0.001):\n",
    "    for step, (x, y) in enumerate(train_dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # 第一层计算， [b, 784]@[784, 256] + [256] => [b, 256] + [256] => [b,256] + [b, 256]\n",
    "            h1 = x @ w1 + tf.broadcast_to(b1, (x.shape[0], 256))\n",
    "            h1 = tf.nn.relu(h1)  # 通过激活函数\n",
    "\n",
    "            # 第二层计算， [b, 256] => [b, 128]\n",
    "            h2 = h1 @ w2 + b2\n",
    "            h2 = tf.nn.relu(h2)\n",
    "            # 输出层计算， [b, 128] => [b, 10]\n",
    "            out = h2 @ w3 + b3\n",
    "\n",
    "            # 计算网络输出与标签之间的均方差， mse = mean(sum(y-out)^2)\n",
    "            # [b, 10]\n",
    "            loss = tf.square(y - out)\n",
    "            # 误差标量， mean: scalar\n",
    "            loss = tf.reduce_mean(loss)\n",
    "\n",
    "            # 自动梯度，需要求梯度的张量有[w1, b1, w2, b2, w3, b3]\n",
    "            grads = tape.gradient(loss, [w1, b1, w2, b2, w3, b3])\n",
    "\n",
    "        # 梯度更新， assign_sub 将当前值减去参数值，原地更新\n",
    "        w1.assign_sub(lr * grads[0])\n",
    "        b1.assign_sub(lr * grads[1])\n",
    "        w2.assign_sub(lr * grads[2])\n",
    "        b2.assign_sub(lr * grads[3])\n",
    "        w3.assign_sub(lr * grads[4])\n",
    "        b3.assign_sub(lr * grads[5])    \n",
    "    \n",
    "    return loss.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs):\n",
    "    losses = []\n",
    "    train_dataset = load_data()\n",
    "    w1, b1, w2, b2, w3, b3 = init_paramaters()\n",
    "    for epoch in range(epochs):\n",
    "        loss = train_epoch(epoch, train_dataset, w1, b1, w2, b2, w3, b3, lr=0.001)\n",
    "        print('epoch:', epoch, 'loss:', loss)\n",
    "        losses.append(loss)\n",
    "\n",
    "    x = [i for i in range(0, epochs)]\n",
    "    # 绘制曲线\n",
    "    plt.plot(x, losses, color='blue', marker='s', label='训练')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "273.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
